{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c8d740-f54c-4549-82ab-df9d86ce2b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "returns_df = pd.read_csv('../data/processed/returns.csv')\n",
    "catalog_df = pd.read_csv('../data/processed/catalog.csv')\n",
    "\n",
    "# Create image labels\n",
    "defect_classes = ['Dresses', 'Tops', 'Jackets', 'Pants', 'Skirts', 'Jeans']\n",
    "defective_images_df = returns_df[returns_df['class_name'].isin(defect_classes)][['image_filename']].copy()\n",
    "defective_images_df['label'] = 'Defective'\n",
    "normal_images_df = catalog_df[~catalog_df['image_filename'].isin(defective_images_df['image_filename'])][['image_filename']].copy()\n",
    "normal_images_df = normal_images_df.sample(n=len(defective_images_df), random_state=42)\n",
    "normal_images_df['label'] = 'Normal'\n",
    "image_df = pd.concat([defective_images_df, normal_images_df], ignore_index=True)\n",
    "\n",
    "# Organize images into folders for Keras\n",
    "train_df, val_df = train_test_split(image_df, test_size=0.2, random_state=42, stratify=image_df['label'])\n",
    "BASE_DIR = '../data/images_for_model/'\n",
    "SOURCE_IMAGE_DIR = '../data/raw/images/'\n",
    "\n",
    "def organize_images(df, split_name):\n",
    "    split_dir = os.path.join(BASE_DIR, split_name)\n",
    "    if os.path.exists(split_dir): shutil.rmtree(split_dir)\n",
    "    for _, row in df.iterrows():\n",
    "        label_dir = os.path.join(split_dir, row['label'])\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        source_path = os.path.join(SOURCE_IMAGE_DIR, row['image_filename'])\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, os.path.join(label_dir, row['image_filename']))\n",
    "\n",
    "organize_images(train_df, 'train')\n",
    "organize_images(val_df, 'validation')\n",
    "\n",
    "# Create Keras datasets\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(os.path.join(BASE_DIR, 'train'), image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(os.path.join(BASE_DIR, 'validation'), image_size=IMG_SIZE, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Build and train the model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_dataset, epochs=10, validation_data=validation_dataset)\n",
    "\n",
    "# Save the model\n",
    "model.save('../models/image_classifier_model.keras')\n",
    "print(\"\\n--- IMAGE MODEL TRAINED AND SAVED ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573f450d-0d63-458c-a0f9-ef7f3848b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 1. Check the current working directory\n",
    "current_directory = os.getcwd()\n",
    "print(f\"This notebook's current location is: {current_directory}\\n\")\n",
    "\n",
    "# 2. Define the path we are trying to check\n",
    "processed_folder_path = '../data/processed'\n",
    "print(f\"Checking for the folder at this relative path: {processed_folder_path}\")\n",
    "\n",
    "# 3. Check if the folder and files exist\n",
    "try:\n",
    "    # Get the absolute path for clarity\n",
    "    abs_path = os.path.abspath(processed_folder_path)\n",
    "    print(f\"This translates to the absolute path: {abs_path}\\n\")\n",
    "    \n",
    "    files = os.listdir(processed_folder_path)\n",
    "    if files:\n",
    "        print(\"SUCCESS: The 'processed' folder was found and it contains:\")\n",
    "        for file in files:\n",
    "            print(f\"- {file}\")\n",
    "    else:\n",
    "        print(\"ERROR: The 'processed' folder exists, but it is EMPTY.\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(\"CRITICAL ERROR: The '../data/processed' folder DOES NOT EXIST.\")\n",
    "    print(\"This is why the error is happening. Please run the '01_data_preparation.ipynb' notebook first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5be85a-1e82-4d28-a8e6-1a2100d0ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll create our own labels. A simple rule: returns for classes that often have\n",
    "# physical quality complaints will be our \"Defective\" examples.\n",
    "defect_classes = ['Dresses', 'Tops', 'Jackets', 'Pants', 'Skirts', 'Jeans']\n",
    "defective_images_df = returns_df[returns_df['class_name'].isin(defect_classes)][['image_filename']].copy()\n",
    "defective_images_df['label'] = 'Defective'\n",
    "\n",
    "# For \"Normal\" images, we'll sample from the main catalog, ensuring they are not in the defective list\n",
    "normal_images_df = catalog_df[~catalog_df['image_filename'].isin(defective_images_df['image_filename'])][['image_filename']].copy()\n",
    "# Let's balance our dataset by sampling a similar number of normal images\n",
    "normal_images_df = normal_images_df.sample(n=len(defective_images_df), random_state=42)\n",
    "normal_images_df['label'] = 'Normal'\n",
    "\n",
    "# Combine them into a single dataframe\n",
    "image_df = pd.concat([defective_images_df, normal_images_df], ignore_index=True)\n",
    "print(f\"Created a labeled dataset of {len(image_df)} images.\")\n",
    "print(image_df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ba758-7481-49c8-9ba8-1f29610f277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras works best when images are in folders like: train/Normal, train/Defective, etc.\n",
    "# This cell will create this structure and copy the images.\n",
    "\n",
    "# First, split our dataframe\n",
    "train_df, val_df = train_test_split(image_df, test_size=0.2, random_state=42, stratify=image_df['label'])\n",
    "\n",
    "# Define the new base directory for our sorted images\n",
    "BASE_DIR = '../data/images_for_model/'\n",
    "\n",
    "# Function to copy images\n",
    "def organize_images(df, split_name):\n",
    "    split_dir = os.path.join(BASE_DIR, split_name)\n",
    "    # Remove existing directory to start fresh\n",
    "    if os.path.exists(split_dir):\n",
    "        shutil.rmtree(split_dir)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        label_dir = os.path.join(split_dir, row['label'])\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        \n",
    "        source_path = os.path.join(SOURCE_IMAGE_DIR, row['image_filename'])\n",
    "        dest_path = os.path.join(label_dir, row['image_filename'])\n",
    "        \n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy(source_path, dest_path)\n",
    "\n",
    "# Organize the training and validation images\n",
    "print(\"Organizing training images...\")\n",
    "organize_images(train_df, 'train')\n",
    "print(\"Organizing validation images...\")\n",
    "organize_images(val_df, 'validation')\n",
    "print(\"Image organization complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70142113-0a24-4a3b-a7b1-790dcab9de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's load these organized images into a format Keras can use\n",
    "IMG_SIZE = (160, 160)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(BASE_DIR, 'train'),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    os.path.join(BASE_DIR, 'validation'),\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Configure datasets for performance\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283386c-9170-479e-ba85-985c10ca5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a powerful pre-trained model (MobileNetV2) and fine-tune it for our task.\n",
    "# This is called Transfer Learning.\n",
    "\n",
    "# 1. Create a data augmentation layer\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "# 2. Load the pre-trained base model\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "base_model.trainable = False # Freeze the base model\n",
    "\n",
    "# 3. Build our final model\n",
    "inputs = keras.Input(shape=(160, 160, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = tf.keras.applications.mobilenet_v2.preprocess_input(x) # Preprocess input for MobileNetV2\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x) # Sigmoid for binary classification\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# 4. Compile the model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d48265e-767f-4bf6-ab2b-42f9d93cbef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we fit the model to our data\n",
    "initial_epochs = 10\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=initial_epochs,\n",
    "    validation_data=validation_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399e408-cfab-4a08-b3bf-94d9d6124bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later use in our final application\n",
    "model.save('../models/image_classifier_model.keras')\n",
    "\n",
    "print(\"Image classification model saved successfully in the 'models' folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
